# -*- coding: utf-8 -*-
"""atividade nº5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dR8Y0CL1-LoG2XZJIVm7ut8NX0AmQ-Gt
"""


#Importar as bibliotecas necessárias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
from collections import Counter
from scipy.stats import mode
from google.colab import drive

#Abrir o arquivo
base = pd.read_csv('montains_beach.xlsx')

#consulta o arquivo
base

# Definindo os resultados esperados e previstos
expected_results = [1, 1, 1, 0, 0, 0, 0, 0, 1]# Resultados esperados
predicted_results = [1, 1, 0, 0, 0, 0, 0, 1, 1] # Resultados previstos

#Verificar dados nulos ou inconsistentes
print("Valores nulos nos resultados esperados:", np.isnan(expected_results).sum())
print("Valores nulos nos resultados previstos:", np.isnan(predicted_results).sum())

#Remover ou substituir valores nulos (se houver)
# Remover valores nulos
expected_results = [x for x in expected_results if x is not None]
predicted_results = [x for x in predicted_results if x is not None]

#Converter os dados para o formato consistente
expected_results = list(map(int, expected_results))
predicted_results = list(map(int, predicted_results))

#Análise básica - contagem de classes
print("Distribuição nos resultados esperados:", Counter(expected_results))
print("Distribuição nos resultados previstos:", Counter(predicted_results))

#Criar e exibir uma tabela de frequências
# Criar um DataFrame com os dados esperados e previstos
df = pd.DataFrame({"Esperado": expected_results, "Previsto": predicted_results})

#Exibir a tabela de frequências cruzada
tabela_frequencias = pd.crosstab(df["Esperado"], df["Previsto"], rownames=["Esperado"], colnames=["Previsto"])
print("Tabela de Frequências:")
print(tabela_frequencias)

#Calcular métricas de avaliação
accuracy = accuracy_score(expected_results, predicted_results)
precision = precision_score(expected_results, predicted_results, average='binary')
recall = recall_score(expected_results, predicted_results, average='binary')
f1 = f1_score(expected_results, predicted_results, average='binary')

print(f"Precisão (Accuracy): {accuracy:.2f}")
print(f"Precisão (Precision): {precision:.2f}")
print(f"Revocação (Recall): {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

# Calculando a matriz de confusão
conf_matrix = confusion_matrix(expected_results, predicted_results)

# Plotando a matriz de confusão
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Montanha (Pred)", "Praia (Pred)"],
            yticklabels=["Montanha (Esperado)", "Praia (Esperado)"])
plt.xlabel("Resultados Previstos")
plt.ylabel("Resultados Esperados")
plt.title("Matriz de Confusão")
plt.show()

#Normalizar e desenhar a matriz de confusão
conf_matrix_normalized = confusion_matrix(expected_results, predicted_results, normalize='true')

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt=".2f", cmap="Blues", cbar=False,
            xticklabels=["Montanha (Pred)", "Praia (Pred)"],
            yticklabels=["Montanha (Esperado)", "Praia (Esperado)"])
plt.xlabel("Resultados Previstos")
plt.ylabel("Resultados Esperados")
plt.title("Matriz de Confusão Normalizada")
plt.show()